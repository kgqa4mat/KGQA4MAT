{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f17b5ae-6b3d-4973-96ae-46d183d3ac2d",
   "metadata": {},
   "source": [
    "# QALD Data Question and Query Translation\n",
    "- Method 0: Answer the QALD-9 questions directly. Instruct ChatGPT to answer the QALD-9 questions directly without querying DBpedia\n",
    "- Method 1: Translate QALD-9 questions directly. Instruct ChatGPT to translate QALD-9 questions directly, and then query DBpedia using the translated queries.\n",
    "- Method 2: 1-shot learning from a pair of train question and query. Using the embeddings of the test and train questions to find the most similar train question to the test question. Prompt ChatGPT with the pair of matched train question and query. Instruct ChatGPT to translate a test question to a SPARQL query over DBpedia.\n",
    "- Method 3: 1-shot learning from a pair of train question and query, and the chain-of-thought of the train query. As in Method 2, include the chain-of-thought of the train query in the prompt, in addition to the pair of matched question and query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e3cf8c-7018-4f63-bc93-7df8349be3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json, re, os, nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3909dede-6cba-4c3c-a03e-87011f7980bb",
   "metadata": {},
   "source": [
    "## Pre-processing QALD Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78113bf-ece5-4044-bc1f-6cc3a7bbb9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/QALD/9/data/qald-9-train-multilingual.json', 'r') as file:\n",
    "    train_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8286581-9953-4160-a408-f39e3b809e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all = pd.DataFrame(train_json['questions'])\n",
    "train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac61e2a-1628-4472-9693-d63cf8705c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012f5ff-4bb2-4ea0-b7f9-31b7734ec45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all.question[39]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4bf1d8-0a69-4979-9abe-d81ed299897d",
   "metadata": {},
   "source": [
    "### Flatten the QALD train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5b93df-e267-434a-8361-057bb6c7c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "keywords = []\n",
    "for idx, row in train_all.iterrows():\n",
    "    question = row['question']\n",
    "    for q in question:\n",
    "        try:\n",
    "            if q['language'] == 'en':\n",
    "                questions.append(q['string'])\n",
    "                keywords.append(q['keywords'])\n",
    "                break\n",
    "        except:\n",
    "            print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff83b155-6a7a-4dce-8ac8-9613f4c01bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions), len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96314a0c-83af-4bcf-a5c0-78809e7c2a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = train_all['query'].apply(lambda r: r['sparql'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3d160-780d-47bd-a287-cb450b064e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881e9b7-44a3-402a-be2b-db6f2bd3f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = train_all['answers'].apply(lambda r: r[0]).apply(lambda p: p['head']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312f30d-1322-4fd0-9324-326c835a38c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = train_all['answers'].apply(lambda r: r[0]).apply(lambda p: p['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fee46-8c79-48f7-aedf-4bb72ce4ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['question_text'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d1397-620c-4171-97ad-5cb6ea3d1f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['sparql_query'] = queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32548323-d196-4799-8f35-2a15ead6698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['question_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09624f3-953e-4ca3-986e-cfafe3e32c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['answer_head'] = heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f41182-08b4-4e4a-a603-a9dc99b2ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all['answer_results'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550d8bd-c39f-4eb2-a344-ccce96847b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_all[['id', 'answertype', 'aggregation', 'onlydbo', 'hybrid', 'question_text', \n",
    "#           'question_keywords', 'sparql_query', 'answer_head', 'answer_results', 'question', \n",
    "#           'query', 'answers']].to_csv('../data/QALD/9/data/qald-9-train.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfdc48-7bd0-4e8e-9ec9-abdbcb9a8874",
   "metadata": {},
   "source": [
    "## Pre-processing QALD Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac48265-663a-411c-a287-5c8e67231861",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/QALD/9/data/qald-9-test-multilingual.json', 'r') as file:\n",
    "    test_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3caa518-59c6-4577-92c8-908862d93c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = pd.DataFrame(test_json['questions'])\n",
    "test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ff5df-db38-46bf-9caf-2b4c6760938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd563a-1c4b-4f11-b988-14d115717fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all.question[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98f6c9-0670-489a-a728-d2191746d5c6",
   "metadata": {},
   "source": [
    "### Flatten the QALD test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5ca023-0ec6-4d64-87f7-8ad88a52d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "keywords = []\n",
    "for idx, row in test_all.iterrows():\n",
    "    question = row['question']\n",
    "    for q in question:\n",
    "        try:\n",
    "            if q['language'] == 'en':\n",
    "                questions.append(q['string'])\n",
    "                keywords.append(q['keywords'])\n",
    "                break\n",
    "        except:\n",
    "            print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c716e-f9ab-4ab7-81cd-1a9353d19c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions), len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd53cc-2c3a-4381-a878-b09f0ea16b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = test_all['query'].apply(lambda r: r['sparql'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023e6e9-b6cc-4326-8c7e-1c3462d42403",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed6bed-3afb-4698-9dbb-991a7e1e9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = test_all['answers'].apply(lambda r: r[0]).apply(lambda p: p['head']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa2af89-6dbf-4cac-8328-d387d5edc687",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_all['answers'].apply(lambda r: r[0]).apply(lambda p: p['results'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5583c6c1-7a8d-43f1-a025-dcef3fd247e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['question_text'] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee06f8e-0894-49e5-95f4-dfc78ea94b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['sparql_query'] = queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ccfa24-7167-40e9-b319-535efcf5a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['question_keywords'] = keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d4143d-ffe8-4a14-bfd4-7ce3896dd608",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['answer_head'] = heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb930449-e41a-40b0-a4bd-e5053974542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all['answer_results'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf3b98-d2c4-4211-896d-7240e8b09ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_all[['id', 'answertype', 'aggregation', 'onlydbo', 'hybrid', 'question_text', \n",
    "#           'question_keywords', 'sparql_query', 'answer_head', 'answer_results', 'question', \n",
    "#           'query', 'answers']].to_csv('../data/QALD/9/data/qald-9-test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87780c64-d9eb-4c96-8285-740733f44a00",
   "metadata": {},
   "source": [
    "## Load the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaded7b4-f969-4c0a-8c83-b193cc6c43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/QALD/9/data/qald-9-train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff79480-f620-47cc-96af-8f9dd1a4ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/QALD/9/data/qald-9-test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62ac0e-59dd-4702-944f-10e17d590cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/QALD/9/data/qald-9-test-multilingual.json', 'r') as file:\n",
    "    test_json = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffd86c4-c63e-4da7-b3ba-95cb59434777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_json_df = pd.DataFrame(test_json['questions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de162b5-7a91-4513-aeea-7cfd821cfbb0",
   "metadata": {},
   "source": [
    "## Ask Test Questions through GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a683be8a-9b4b-4572-934b-5f127cf9421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "openai_key_path = \"OPENAI_KEY_PATH\"\n",
    "with open(openai_key_path, 'r') as f:\n",
    "    openai_key = f.readline()\n",
    "# My OpenAI Key\n",
    "os.environ['OPENAI_API_KEY'] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f6b51-ccde-4b2e-b4b5-777d5fdc7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc723f0-61be-4aa7-8b22-d9b7987807c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c9ccbf-456e-4771-9aee-02de1d0e02ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt_answers = []\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    question_text = row['question_text']\n",
    "    keywords = row['question_keywords']\n",
    "    \n",
    "    answertype = row['answertype']\n",
    "    answertype_text = \"\"\n",
    "    if answertype == 'resource':\n",
    "        answertype_text = 'resource in DBpedia-2016-04'\n",
    "    else:\n",
    "        answertype_text = answertype\n",
    "    \n",
    "    answeragg = row['aggregation']\n",
    "    answeragg_text = \"The answers do not need aggregation\"\n",
    "    if answeragg:\n",
    "        answeragg_text = \"The answers need aggregration\"\n",
    "        \n",
    "    prompt_template = \"Use DBpedia-2016-04 knowledge base. \\\n",
    "        Answer the question. No comments. List answers only. \\n \\\n",
    "        The keywords in the question are \\\"{}\\\". \\n\\\n",
    "        Output the answers as {}. \\n\\\n",
    "        {}. \\n\\\n",
    "        QUESTION: {} \\n \\\n",
    "        ANSWER: \\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(keywords, answertype_text, answeragg_text, \n",
    "                                    question_text)\n",
    "    \n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        #model=\"text-curie-001\",\n",
    "        #model=\"text-davinci-003\",\n",
    "        prompt= prompt,\n",
    "        #prompt=question_text,\n",
    "        temperature=0.1,\n",
    "        max_tokens=3500,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    gpt_answers.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94351cb7-6228-4902-9145-8f01e5f5278c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(gpt_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364528f8-002a-415e-bade-965498899680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd266c5-acf8-47e5-bfb4-cf103e5a2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/QALD/9/data/qald-test-qpt3-answers-question-keywords.pk', 'wb') as f:\n",
    "    #pickle.dump(gpt_answers, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bee1ca-04bf-4b83-ad15-defb221b8898",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate the GPT_Answers on Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70341a1e-b74b-4179-9e75-f2d551dbd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/QALD/9/data/qald-test-qpt3-answers-question-keywords.pk', 'rb') as f:\n",
    "    gpt_answers = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac13367-5d97-49e9-9676-03137f610f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpt_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44be35a4-b515-4ebe-873a-e4b14ebae203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the answer terms from gpt_answer_text\n",
    "gpt_answer_terms = []\n",
    "for idx, row in test.iterrows():\n",
    "    answers_text = row['gpt_answers_text']\n",
    "    terms = answers_text.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower().split('\\n')\n",
    "    #terms = answers_text.strip().lower().split('\\n')\n",
    "    gpt_answer_terms.append([t.strip() for t in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c029a65-d233-4e9c-a2bb-d2a4ef9896e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gpt_answer_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45635fd1-f3cd-4b32-b825-bef9417006c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "gpt_answer_terms_parsed = []\n",
    "for terms in gpt_answer_terms:\n",
    "    terms_parsed = []\n",
    "    for term in terms:\n",
    "        parsed_string = urllib.parse.unquote(term)\n",
    "        terms_parsed.append(parsed_string)\n",
    "    gpt_answer_terms_parsed.append(terms_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46f6434-1ed5-4824-8c80-36b965798519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpt_answer_terms_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26bf203-6fb7-4595-9a00-de7a072cb9ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_terms = []\n",
    "count = 0\n",
    "for idx, row in test_json_df.iterrows():\n",
    "    try:\n",
    "        bindings = row['answers'][0]['results']['bindings']\n",
    "\n",
    "        answer_list = []\n",
    "        for item in bindings:\n",
    "            for k in item:\n",
    "                answer_list.append(item[k]['value'])\n",
    "\n",
    "        terms = []\n",
    "        for ans in answer_list:\n",
    "            terms.append(ans.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower())\n",
    "        #if terms not in answer_terms:\n",
    "        answer_terms.append(terms)\n",
    "              \n",
    "    except:\n",
    "        answer_terms.append([str(row['answers'][0]['boolean']).lower()])\n",
    "        count += 1\n",
    "        #print(row['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e36b099-b66d-4e79-8e87-afd8ccf51b94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(answer_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ef0a44-dd07-4147-9266-c2dea367c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = 0\n",
    "gold = 0\n",
    "predicted_correct = 0\n",
    "some_matched = {}\n",
    "for idx, pred_terms in enumerate(gpt_answer_terms_parsed):\n",
    "    gold_terms = answer_terms[idx]\n",
    "    \n",
    "    predicted +=  len(pred_terms)\n",
    "    gold += len(gold_terms)\n",
    "    \n",
    "    predicted_correct_idx = 0\n",
    "    for pterm in pred_terms:\n",
    "        if len(pterm) > 0: # skip an empty string\n",
    "            for gterm in gold_terms:\n",
    "                #if pterm ==  gterm:\n",
    "                if (pterm in gterm) or (gterm in pterm):\n",
    "                    predicted_correct_idx += 1\n",
    "                    predicted_correct += 1\n",
    "                    break # skip correct prediction, don't double count anymore\n",
    "                \n",
    "    some_matched[idx] = predicted_correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa41175-ffbb-46fb-b2ba-2192f9677cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = predicted_correct / predicted\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c4d51-f8c7-4053-b4f8-f7a752a1979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = predicted_correct/gold\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9b726-c9f1-43a0-9637-4d447c755d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 / (1/precision + 1/recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa30a3bc-fab4-4804-9920-73dc7e83e602",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use ChatGPT to answer and translate the test questions \n",
    "- Use ChatGPT to answer the questions directly\n",
    "- Use ChatGPT to translate user questions to queries\n",
    "- Use ChatGPT to translate user questions to queries by few-shot learning\n",
    "- Use ChatGPT to translate user questions to queries by few-shot learning and chain of thought"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b97cb-b48c-4669-959e-08fd8d338404",
   "metadata": {},
   "source": [
    "### User ChatGPT to answer the question directly on DBpedia-03132023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ee1f7b-242c-4e31-8340-94fe3e82da0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d7a2f9-5d4e-422e-8e1d-b0606b0bd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"\"\"\n",
    "Answer the question. Output the answer only. No comments in the output. \n",
    "The keywords in the question are \"{}\". \n",
    "Output the answers as \"{}\". \n",
    "If the question cannot be answered using the DBpedia-2016-04 knowledge base, \n",
    "output \"None\".\n",
    "\n",
    "QUESTION: {}\n",
    "\n",
    "ANSWER:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb16b3e-2138-490e-a0ac-36395033615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2740f37-c520-4cfc-843a-bcd0e829df74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_answers = []\n",
    "count = 0\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    question_text = row['question_text']\n",
    "    keywords = row['question_keywords']\n",
    "    \n",
    "    answertype = row['answertype']\n",
    "    answertype_text = \"\"\n",
    "    if answertype == 'resource':\n",
    "        answertype_text = 'DBpedia Resource URI(s)'\n",
    "    else:\n",
    "        answertype_text = answertype\n",
    "    \n",
    "    answeragg = row['aggregation']\n",
    "    answeragg_text = \"The answers do not need aggregation\"\n",
    "    if answeragg:\n",
    "        answeragg_text = \"The answers need aggregration\"\n",
    "        \n",
    "    msg = \"\"\"\n",
    "        Answer the question. No comments. List answers only.  \n",
    "        The keywords in the question are {}. \n",
    "        Output the answers as {}. \n",
    "\n",
    "        QUESTION: {}\n",
    "\n",
    "        ANSWER: \n",
    "    \"\"\"\n",
    "    \n",
    "    msg = msg.format(keywords, answertype_text, question_text)\n",
    "    \n",
    "    #print(msg)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant using \\\n",
    "               DBpedia to answer questions.\"},\n",
    "            {\"role\": \"user\", \"content\": msg}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chatgpt_answers.append(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5695bc3e-bff9-4069-bc2e-90156c037887",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_answers_text_DBpedia_2023_03'] = chatgpt_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcd917-8a0b-4447-b459-72ebc9647eb6",
   "metadata": {},
   "source": [
    "#### Evaluate the results of using ChatGPT to answer the questions directly on DBpedia-03132023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a846c1a-f97c-4d90-8a70-1540765ae1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the answer terms from gpt_answer_text\n",
    "chatgpt_answer_terms = []\n",
    "for idx, row in test.iterrows():\n",
    "    answers_text = row['chatgpt_answers_text_DBpedia_2023_03']\n",
    "    terms = answers_text.replace('https://dbpedia.org/resource/', '').\\\n",
    "    replace('http://dbpedia.org/resource/', '').\\\n",
    "    replace('dbo:', '').strip().lower().split('\\n')\n",
    "    #terms = answers_text.strip().lower().split('\\n')\n",
    "    chatgpt_answer_terms.append([t.strip() for t in terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a953e94-498a-4f24-9653-56607ccd40c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eee7a1-170e-4532-bc5a-37b01c065059",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_answer_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7979e79-bb38-48a7-acd7-a1ad1251a408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "chatgpt_answer_terms_parsed = []\n",
    "for terms in chatgpt_answer_terms:\n",
    "    terms_parsed = []\n",
    "    for term in terms:\n",
    "        parsed_string = urllib.parse.unquote(term)\n",
    "        terms_parsed.append(parsed_string)\n",
    "    chatgpt_answer_terms_parsed.append(terms_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c915f-f5aa-47cb-8ea7-4af95299103d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_answer_terms_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3864dc-7e73-48f1-bac6-078bc89f4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd8f27f-dc49-49bc-a2b8-eb437945d51d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_terms = []\n",
    "count = 0\n",
    "for idx, row in test_json_df.iterrows():\n",
    "    try:\n",
    "        bindings = row['answers'][0]['results']['bindings']\n",
    "\n",
    "        answer_list = []\n",
    "        for item in bindings:\n",
    "            for k in item:\n",
    "                answer_list.append(item[k]['value'])\n",
    "\n",
    "        terms = []\n",
    "        for ans in answer_list:\n",
    "            terms.append(ans.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower())\n",
    "        #if terms not in answer_terms:\n",
    "        answer_terms.append(terms)\n",
    "              \n",
    "    except:\n",
    "        answer_terms.append([str(row['answers'][0]['boolean']).lower()])\n",
    "        count += 1\n",
    "        #print(row['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab92def-d4ca-416f-9859-0985453566d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(answer_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3883aa2-5a72-48ae-8f71-8674b3a038cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answer_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f6592d-119d-49f3-9ad6-d13923b9685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the precision and recall based on the total numbers of \n",
    "# gold answers and predicted answers\n",
    "predicted = 0\n",
    "gold = 0\n",
    "predicted_correct = 0\n",
    "some_matched = {}\n",
    "pre_gold_lengths = []\n",
    "for idx, pred_terms in enumerate(chatgpt_answer_terms_parsed):\n",
    "    gold_terms = answer_terms[idx]\n",
    "    \n",
    "    predicted +=  len(pred_terms)\n",
    "    gold += len(gold_terms)\n",
    "    \n",
    "    pre_gold_lengths.append((idx, len(pred_terms), len(gold_terms)))\n",
    "    \n",
    "    predicted_correct_idx = False\n",
    "    for pterm in pred_terms:\n",
    "        if len(pterm) > 0: # skip an empty string\n",
    "            for gterm in gold_terms:\n",
    "                #if pterm ==  gterm:\n",
    "                pterm = pterm.replace(\"_\", \" \")\n",
    "                gterm = gterm.replace(\"_\", \" \")\n",
    "                if (pterm in gterm) or (gterm in pterm):\n",
    "                    predicted_correct_idx = True\n",
    "                    predicted_correct += 1\n",
    "                    break # this pterm is a correct prediction, skip to next pterm\n",
    "                          # don't double count this pterm anymore\n",
    "                \n",
    "    some_matched[idx] = predicted_correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e907e-b5f8-4eff-87e1-7ce831dea4d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_gold_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a00ad1a-8d6f-445f-8fc5-2e5d6fe9e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = predicted_correct / predicted\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbbcb41-bb0b-4825-b2e7-45eaedc58a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = predicted_correct/gold\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0284e-9acf-4e5b-b0f0-1307bd5edd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 / (1/precision + 1/recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d255f-dc3f-4c80-8fa4-3ca84d0577b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_precision = (predicted_correct-240) / (predicted-240)\n",
    "adj_recall = (predicted_correct-240)/ (gold - 1714)\n",
    "adj_f1 = 2 / (1/adj_precision +  1/adj_recall)\n",
    "print('adj_precision:{},\\nadj_recall:{},\\nadj_f1:{}'.format(adj_precision, adj_recall, adj_f1))\n",
    "predicted_correct, predicted, gold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace616da-647f-4df2-b211-333048f05366",
   "metadata": {},
   "source": [
    "### Use ChatGPT to translate user questions to queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a16e04-035a-40f3-8ae8-64a18b2af3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each the test SPARQL query, query the DBpedia endpoint in\n",
    "# March, 2023\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "gold_query_results = []\n",
    "count = 0\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    gold_query = row['sparql_query']\n",
    "    \n",
    "    sparql.setQuery(gold_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        gold_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        gold_query_results.append('ERROR')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45a1ed-b9f7-4b19-ad1a-62c7c6f2a090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gold_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4d86f-d824-4abb-9aa6-be39a554198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['gold_query_results_03132023'] = gold_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71965497-3bff-4da0-a04b-57a48cf95cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc325d5-9902-4c38-b8b4-8c9348f1672c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ChatGPT translate user questions to SPARQL Queries directly\n",
    "\n",
    "chatgpt_queries = []\n",
    "count = 0\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    question_text = row['question_text']\n",
    "    keywords = row['question_keywords']\n",
    "    \n",
    "    answertype = row['answertype']\n",
    "    answertype_text = \"\"\n",
    "    if answertype == 'resource':\n",
    "        answertype_text = 'DBpedia Resource URI(s)'\n",
    "    else:\n",
    "        answertype_text = answertype\n",
    "    \n",
    "    answeragg = row['aggregation']\n",
    "    answeragg_text = \"The answers do not need aggregation\"\n",
    "    if answeragg:\n",
    "        answeragg_text = \"The answers need aggregration\"\n",
    "        \n",
    "    msg = \"\"\"\n",
    "        Translate the following question to SPARQL query on the \n",
    "        DBpedia knowledge base. The output query should include \n",
    "        all necessary prefixes for querying the current DBpedia endpoint. \n",
    "        No comments. Output SPARQL query only.\n",
    "        The query should return answers as {}.\n",
    "        \n",
    "        QUESTION: {} \n",
    "        \n",
    "        QUERY: \n",
    "    \"\"\"\n",
    "    \n",
    "    msg = msg.format(answertype_text, question_text)\n",
    "    \n",
    "    #print(msg)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant focusing on \\\n",
    "             DBpedia. You will translate user questions to SPARQL queries on \\\n",
    "             the current DBpedia knowledge base.\"},\n",
    "            {\"role\": \"user\", \"content\": msg}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chatgpt_queries.append(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b3388-c174-4095-a5a5-34410188c80f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54415cee-56b8-44d7-b54a-1d7d76d9af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_queries_text = [\" \".join(item.split('\\n')).strip() for item in chatgpt_queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b6b78-64b7-4160-9ba2-ec86a2e54a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_query_DBpedia_2023_03'] = chatgpt_queries_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b92094-0be5-4608-91ff-f5617c898a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10e347-fcda-4aa7-83f9-ee2f02c4da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed6191-788e-42fc-a6d6-84634556ca93",
   "metadata": {},
   "source": [
    "#### Retrieve chatgpt_query_results_DBpedia_2023_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3b548-6e6d-4b70-a860-f97062c836a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/QALD/9/data/qald-9-test.csv')\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f66e4-ca4a-4873-99f2-2cc73f49a7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the chatgpt_query_results\n",
    "# For each the test GPT query, query the DBpedia endpoint in\n",
    "# March, 2023\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "chatgpt_query_results = []\n",
    "count = 0\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #   break\n",
    "     \n",
    "    count += 1\n",
    "    chatgpt_query = row['chatgpt_query_DBpedia_2023_03']\n",
    "    \n",
    "    sparql.setQuery(chatgpt_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        chatgpt_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        chatgpt_query_results.append(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2c7041-a977-420b-837a-876c423b7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_query_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302be65-5e79-4dcb-8054-5b1f877b25ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_query_results_DBpedia_2023_03'] = chatgpt_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c9917-bec5-410a-941e-01107c478fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e15b06-5703-471a-9623-dab308705ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f54606-6e4b-4535-8361-627f86ead97a",
   "metadata": {},
   "source": [
    "### Use ChatGPT to translate user questions to queries by few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba84f2-ac51-464a-a924-68f8209c5f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7f0c66-e402-42bf-8a4c-be6cf9a5a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddb8bfd-8c3d-4fc9-ad18-9913afdd53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv')\n",
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494b4cd-6595-42eb-ace1-2ef67405f0d8",
   "metadata": {},
   "source": [
    "#### Embed Train Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a686f-9377-41f3-9118-0d816cef613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from openai.embeddings_utils import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783186d-ade2-4084-b43f-78428b0fc8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b81613-86d4-49e4-a7c1-0e352e182b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n",
    "\n",
    "# This may take a few minutes\n",
    "train_embeddings = []\n",
    "for idx, row in tqdm(train.iterrows(), total=train.shape[0]):\n",
    "    question_text = row['question_text']\n",
    "    \n",
    "    train_embeddings.append(get_embedding(question_text, engine=embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bec8cf-af1c-45b4-98f0-648c3adbd7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['train_question_embedding'] = train_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c7ddc-37c7-4c1b-82a7-4f0ab6cab5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.iloc[9].train_question_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb66b0b-3e89-4680-a116-15146b1013f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb84ba-2440-433d-88be-bda93afc7fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the question embeddings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datafile_path = \"../data/QALD/9/data/qald-9-train.csv\"\n",
    "\n",
    "train = pd.read_csv(datafile_path)\n",
    "train[\"train_question_embedding\"] = train.train_question_embedding.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228f0733-e476-40b4-8fa8-8a2274eeb655",
   "metadata": {},
   "source": [
    "#### Embed test question and search similar train questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d39bf-f7e4-4ff8-8a74-760a99b9330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab7ee2-dbfe-4391-a5df-b77777e3315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_question_query(df, input_question, n=3):\n",
    "    input_question_embedding = get_embedding(\n",
    "        input_question,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.train_question_embedding.apply(lambda x: cosine_similarity(x, input_question_embedding))\n",
    "\n",
    "    results = \\\n",
    "        df.sort_values(\"similarity\", ascending=False) \\\n",
    "        .head(n)[['question_text', 'sparql_query']]\n",
    "    \n",
    "    return input_question_embedding, list(results['question_text'].values), list(results['sparql_query'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1458ab17-1a61-45e2-93d7-836c94dac2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question_embeddings = []\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    test_question = row['question_text']\n",
    "    question_embedding = get_embedding(\n",
    "        test_question,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    test_question_embeddings.append(question_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270bbf4-0e56-4134-b74f-73b29db2927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['test_question_embedding'] = test_question_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6f3a7-669c-4d6c-9456-4532c421bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv('../data/QALD/9/data/qald-9-test.csv')\n",
    "#test[\"test_question_embedding\"] = test.test_question_embedding.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e7403-d70d-4ffc-aa96-0dec299fe068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7efc83-b982-4398-8ace-cceb1cfa07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2d60b-c1bf-4cd4-a6f4-5a74d45de29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"train_question_embedding\"] = train.train_question_embedding.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41cd95-f37c-4fd5-b47f-760c79b6cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b76ade-b264-433a-ad15-b0ef487411f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "train_matched_questions = []\n",
    "train_matched_queries = []\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    test_question_embedding = row['test_question_embedding']\n",
    "    \n",
    "    train_embeddings_similarities = train_embeddings.question_embedding.apply(lambda x: cosine_similarity(x,test_question_embedding))\n",
    "    \n",
    "    max_idx = train_embeddings_similarities.idxmax()\n",
    "    \n",
    "    results = \\\n",
    "        train_embeddings.iloc[max_idx][['question', 'query']]\n",
    "    \n",
    "    matched_question = results['question']\n",
    "    matched_query = results['query']\n",
    "\n",
    "    train_matched_questions.append(matched_question)\n",
    "    train_matched_queries.append(matched_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5341d0be-dd95-4bf5-a25d-19eb94e36517",
   "metadata": {},
   "source": [
    "#### Few-shot learning on matched train question only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef88eaad-ced6-4b55-a4de-58d4edad0a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "chatgpt_train_fewshot_query = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    if count > 4:\n",
    "        break\n",
    "    count += 1\n",
    "    \n",
    "    test_question = row['question_text']\n",
    "\n",
    "    test_question_embedding = row['test_question_embedding']\n",
    "    \n",
    "    train_question_idx = train.index[train['question_text'] == test_question].tolist()\n",
    "    \n",
    "    if len(train_question_idx) > 0: # find a matched train question, skip to generate new query\n",
    "        chatgpt_train_fewshot_query.append(train.iloc[train_question_idx[0]]['sparql_query'])\n",
    "    \n",
    "    else:\n",
    "\n",
    "        train_embeddings_similarities = train.train_question_embedding.\\\n",
    "        apply(lambda x: cosine_similarity(x,test_question_embedding))\n",
    "\n",
    "        top5_idx = train_embeddings_similarities.sort_values(ascending=False)[:5].index\n",
    "\n",
    "        top5_train_questions = list(train.iloc[top5_idx].question_text.values)\n",
    "        top5_train_queries = list(train.iloc[top5_idx].sparql_query.values)\n",
    "\n",
    "        sys_question_query = \"\"\"\n",
    "            Learn the following example question and corresponding query.\n",
    "            \n",
    "            Question: {} \n",
    "            Query: {}\n",
    "        \"\"\"\n",
    "        sys_question_query = sys_question_query.format(top5_train_questions[0], \n",
    "                                                  top5_train_queries[0])\n",
    "    \n",
    "        msg = \"\"\"\n",
    "           Only use the terms defined in the DBpedia ontology. \n",
    "           Translate the following question to SPARQL query. \n",
    "           Output query only. No comments. \n",
    "           Output syntactically correct query only. \n",
    "           Some common prefixes can be used in the query:\n",
    "            PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "            PREFIX dbr: <http://dbpedia.org/resource/>\n",
    "            PREFIX dbc: <http://dbpedia.org/resource/Category:>\n",
    "            PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "            PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "            PREFIX dct: <http://purl.org/dc/terms/>\n",
    "        \n",
    "           Question:{}\n",
    "           Query:\n",
    "        \"\"\"\n",
    "        msg = msg.format(test_question)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on DBpedia. \\\n",
    "            You will translate a user question to a SPARQL on the DBpedia knowledge base.\"},\n",
    "            {\"role\": \"system\", \"content\": sys_question_query},\n",
    "            {\"role\": \"user\", \"content\": msg}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "\n",
    "        chatgpt_train_fewshot_query.append(response['choices'][0]['message']['content'].\\\n",
    "                                   strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164cb34-e87f-4e2c-97d8-4c33dcd51824",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0117c6-dd4d-4dee-9ace-ee8206876733",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25e556-923c-4fd1-bb3c-712b98db030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_train_fewshot_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487e4b5c-2202-4884-afe5-820a2df91166",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea309866-7499-4083-89fa-22b120316658",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_train_1fewshot_query'] = chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84782788-a620-47b1-b164-e24c4a0e5fa5",
   "metadata": {},
   "source": [
    "#### Save train and test embeddings narry in Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f7741-8baa-4efe-8a3c-5eec01006f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[['id', 'answertype', 'aggregation', 'onlydbo', 'hybrid', 'question_text',\n",
    "#       'question_keywords', 'sparql_query', 'train_question_embedding']].\\\n",
    "#to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6eafd-1b24-48fc-a117-135980bea894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test[['id', 'answertype', 'aggregation', 'onlydbo', 'hybrid', 'question_text',\n",
    "#       'question_keywords', 'sparql_query', 'test_question_embedding']].\\\n",
    "#       to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb098e4-b519-4217-927a-47e1de0cfed1",
   "metadata": {},
   "source": [
    "#### Retrieve chatgpt_train_fewshot_query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ca5484-9f84-465f-b3a0-2148159bd6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the chatgpt_train_3fewshot_query_results\n",
    "# query the DBpedia endpoint in\n",
    "# March, 2023\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "chatgpt_train_fewshot_query_results = []\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    chatgpt_train_fewshot_query = row['chatgpt_train_1fewshot_query']\n",
    "    \n",
    "    sparql.setQuery(chatgpt_train_fewshot_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        chatgpt_train_fewshot_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        chatgpt_train_fewshot_query_results.append(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993b2fd-db8f-4f1b-976d-7873866316f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.iloc[125].sparql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae303f7-77fe-4190-800c-c93b6da538e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_train_fewshot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751e8f6b-5d56-41cb-b2a6-5e758af0d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_train_1fewshot_query_results'] = chatgpt_train_fewshot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9776a12-3569-4a27-8a6d-11768f2890bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b785fd28-7923-44a8-90fe-6bfac9a06ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c93b5b-ab6b-4bdd-8217-be98e0ba2007",
   "metadata": {},
   "source": [
    "### Use ChatGPT to translate user questions to queries by few-shot learning WITH MASKED ENTITIEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5760e336-d81e-46fc-8fad-8630dbd66e11",
   "metadata": {},
   "source": [
    "#### First, mask entities in train and test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b982ad-56e6-4faa-8833-19cb7c488e2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "masked_results = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if count > 20:\n",
    "    #    break\n",
    "    #count += 1\n",
    "    \n",
    "    if (idx > -1) and (idx < 200):\n",
    "    #if idx < 3:\n",
    "        t_question = row['question_text']\n",
    "        t_query = row['sparql_query']\n",
    "\n",
    "        question_keywords = row['question_keywords']\n",
    "\n",
    "        msg = \"\"\"\n",
    "            Identify any named entities in the question and replace \n",
    "            the discovered named entities with [MASK1], [MASK2], etc.\n",
    "            One mask for each named entity only.\n",
    "            Merge consecutive masks into one mask.\n",
    "            No comments. Output masked question only.\n",
    "           \n",
    "            Question:{}\n",
    "            Masked Question:\n",
    "        \"\"\"\n",
    "        msg = msg.format(t_question)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on\\\n",
    "                identifying named entities and replacing them with masks.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        masked_results.append(response['choices'][0]['message']['content'])\n",
    "                                   #strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0ddbc6-f623-49ac-931d-15aa559b6eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dec316-5bb4-4f5b-b332-03d5563e0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/QALD/9/data/test_masked_questions.txt', 'w') as file:\n",
    "#    for item in masked_results:\n",
    "#        file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0a0db-6578-4e06-98a3-730a5f6732bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_cleaned = []\n",
    "with open('../data/QALD/9/data/test_masked_questions.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        masked_cleaned.append(line.strip())\n",
    "masked_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c52ddf-f3a0-4245-961e-4b624f54ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masked_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af138787-968d-4f5d-9a6c-77591d0f8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['masked_question'] = masked_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406e525-9ea8-4274-a76a-375675227607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d9c3a-dde1-45a3-9fc3-91f31abd785f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "masked_results = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(train.iterrows(), total=train.shape[0]):\n",
    "    \n",
    "    #if count > 20:\n",
    "    #    break\n",
    "    #count += 1\n",
    "    \n",
    "    if (idx > 381 ) and (idx < 383):\n",
    "    #if idx < 3:\n",
    "        t_question = row['question_text']\n",
    "        t_query = row['sparql_query']\n",
    "\n",
    "        question_keywords = row['question_keywords']\n",
    "\n",
    "        msg = \"\"\"\n",
    "            Identify any named entities in the SPARQL query and replace \n",
    "            the identified named entities with [MASK1], [MASK2], etc.\n",
    "            One mask for each named entity only.\n",
    "            Merge consecutive masks into one mask.\n",
    "            Output masked query only. No comments. \n",
    "           \n",
    "            Query:{}\n",
    "            Masked Query:\n",
    "        \"\"\"\n",
    "        msg = msg.format(t_query)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on\\\n",
    "                identifying named entities and replacing them with masks.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        masked_results.append(response['choices'][0]['message']['content'])\n",
    "                                   #strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74802c89-7f51-4f68-bb06-6d1f89d13813",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55893ac3-a4dd-482f-9e08-42e1cb785bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masked_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5f2d3-d9f0-455d-8ba3-003c1739ea1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#masked_20 = []\n",
    "for item in masked_results:\n",
    "    masked_20.append(item)\n",
    "masked_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ae33dc-a8e0-42fd-bb6a-15445b3891da",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masked_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f6b9a-9117-427f-b373-5547f2983f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../data/QALD/9/data/test_masked_queries.txt', 'w') as file:\n",
    "#    for item in masked_20:\n",
    "#        file.write(item + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296b21f-1d1f-4898-90fb-04f5c7a46a93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_cleaned = []\n",
    "with open('../data/QALD/9/data/train_masked_queries.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        if len(line) > 0:\n",
    "            masked_cleaned.append(line.strip())\n",
    "masked_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40cfbbc-d5be-4899-8adb-089b69a7bd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masked_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c689b9d-7dbc-4573-aaee-3e1e474b5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['masked_query'] = masked_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02172696-f528-437f-b738-5acdffa7c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f54c94-cb3e-40b8-9ce3-d965b714930c",
   "metadata": {},
   "source": [
    "### Get Chain of Thought for train and test masked queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e05c58-143a-4187-b68d-046bb161cb47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "masked_cot = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(train.iterrows(), total=train.shape[0]):\n",
    "    \n",
    "    #if count > 4:\n",
    "    #    break\n",
    "    count += 1\n",
    "    \n",
    "    if (idx > 381) and (idx < 383):\n",
    "    #if idx < 3:\n",
    "        m_query = row['masked_query']\n",
    "\n",
    "\n",
    "        msg = \"\"\"\n",
    "               Briefly explain the following query in logical steps as a chain of thought. \n",
    "               Explain in natural language. \n",
    "               Forget what you have about the query before. \n",
    "               Assume you are trying to construct the query again.\n",
    "               Treat the mask variables, [MASK1], [MASK2] as real entities.\n",
    "               No comments. Output the steps only. \n",
    "               Do not include the original query in the explanation. \n",
    "\n",
    "               QUERY:{}\n",
    "               THOUGHT:\n",
    "        \"\"\"\n",
    "        msg = msg.format(m_query)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on DBpedia. \\\n",
    "                 You will explain a masked SPARQL query in logical steps to help reconstruct the query. \"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        masked_cot.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31de971-42f6-4c3a-aacf-9a09d318446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(masked_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e612e4-c4bd-43aa-b60a-ef829b98ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['masked_cot']=masked_cot_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25894e2e-91f5-4271-bfe8-9e2ae9e3a70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d478d4-70b9-4af4-bfaa-bc3854509d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "masked_cot = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if count > 4:\n",
    "    #    break\n",
    "    count += 1\n",
    "    \n",
    "    if (idx > 99) and (idx < 200):\n",
    "    #if idx < 3:\n",
    "        m_query = row['masked_query']\n",
    "\n",
    "\n",
    "        msg = \"\"\"\n",
    "               Briefly explain the following query in logical steps as a chain of thought. \n",
    "               Explain in natural language. \n",
    "               Forget what you have about the query before. \n",
    "               Assume you are trying to construct the query again.\n",
    "               Treat the mask variables, [MASK1], [MASK2] as real entities.\n",
    "               No comments. Output the steps only. \n",
    "               Do not include the original query in the explanation. \n",
    "\n",
    "               QUERY:{}\n",
    "               THOUGHT:\n",
    "        \"\"\"\n",
    "        msg = msg.format(m_query)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on DBpedia. \\\n",
    "                 You will explain a masked SPARQL query in logical steps to help reconstruct the query. \"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        masked_cot.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6ae99-50d8-40ba-b1f6-e7e52d9c246e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "masked_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5653a4f-25df-418b-8f32-cac132544f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['masked_cot']=masked_cot_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8ee706-6de0-4a2a-a339-4e714b33aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803756f-7504-44c5-ac05-c46e2a394bd7",
   "metadata": {},
   "source": [
    "### Embed Train Masked Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7b30a8-4551-45b7-9d06-c9499b6baf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from openai.embeddings_utils import get_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b51cc-04aa-4e5d-919e-40c2aad48e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86e2fd0-4053-4d72-918c-898f8e335e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have your API key set in your environment per the README: https://github.com/openai/openai-python#usage\n",
    "\n",
    "# This may take a few minutes\n",
    "train_masked_embeddings = []\n",
    "for idx, row in tqdm(train.iterrows(), total=train.shape[0]):\n",
    "    question_text = row['masked_question']\n",
    "    \n",
    "    train_masked_embeddings.append(get_embedding(question_text, engine=embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd91604e-9646-459a-b099-57dd874a6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['train_masked_question_embedding'] = train_masked_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72616894-204c-4ba2-993c-171838e120d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa0e40-e0ad-41f4-9ef1-ffee1658a584",
   "metadata": {},
   "source": [
    "### Embed test question and search similar train questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbdaf3c-1f47-4be5-b776-5f1a4c1d8313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd7ac07-0f20-4ce9-b13f-9296ae50eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search through the train for matched question\n",
    "def search_question(df, input_question, n=3, pprint=True, masked=False):\n",
    "    input_question_embedding = get_embedding(\n",
    "        input_question,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    if masked:\n",
    "        df[\"similarity\"] = df.train_masked_question_embedding.apply(lambda x: cosine_similarity(x, input_question_embedding))\n",
    "    else:\n",
    "        df[\"similarity\"] = df.train_question_embedding.apply(lambda x: cosine_similarity(x, input_question_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .head(n)[['question_text', 'masked_question']]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    #if pprint:\n",
    "    #    for r in results:\n",
    "    #        print(r[:200])\n",
    "    #        print()\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479f1c4-3ee3-46a1-a239-699a4046823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_question_query(df, input_question, n=3, masked=False):\n",
    "    input_question_embedding = get_embedding(\n",
    "        input_question,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    if masked:\n",
    "        df[\"similarity\"] = df.train_masked_question_embedding.apply(lambda x: cosine_similarity(x, input_question_embedding))\n",
    "    else:\n",
    "        df[\"similarity\"] = df.train_question_embedding.apply(lambda x: cosine_similarity(x, input_question_embedding))\n",
    "\n",
    "    results = \\\n",
    "        df.sort_values(\"similarity\", ascending=False) \\\n",
    "        .head(n)[['question_text', 'sparql_query', 'masked_question', 'masked_query']]\n",
    "    \n",
    "    return input_question_embedding, list(results['question_text'].values), list(results['sparql_query'].values),\\\n",
    "                  list(results['masked_question'].values), list(results['masked_query'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2ef31-5f63-4376-9cd6-b5a9f6535223",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question_embeddings = []\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    test_question = row['masked_question']\n",
    "    question_embedding = get_embedding(\n",
    "        test_question,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    test_question_embeddings.append(question_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4359ee4-d517-4626-b00e-0db90556a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['test_question_embedding'] = test_question_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e722ccb7-e444-4b6a-aaee-451c946692b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = pd.read_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv')\n",
    "#test[\"test_question_embedding\"] = test.test_question_embedding.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f3d4a8-9cc9-4c47-a865-d2b950d38095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test.csv-with-embeddings-cot', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852b6702-43c1-4897-b620-f90ffb5eac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2e203-a68c-413d-8190-ed3f8f41cf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[\"train_question_embedding\"] = train.train_question_embedding.apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb55b9-2184-4f1d-af09-1f58bb9ba4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e23d167-09e0-48ad-bed4-942bafa861d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "train_matched_questions = []\n",
    "train_matched_queries = []\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    test_question_embedding = row['test_question_embedding']\n",
    "    \n",
    "    train_embeddings_similarities = train_embeddings.question_embedding.apply(lambda x: cosine_similarity(x,test_question_embedding))\n",
    "    \n",
    "    max_idx = train_embeddings_similarities.idxmax()\n",
    "    \n",
    "    results = \\\n",
    "        train_embeddings.iloc[max_idx][['question', 'query']]\n",
    "    \n",
    "    matched_question = results['question']\n",
    "    matched_query = results['query']\n",
    "\n",
    "    train_matched_questions.append(matched_question)\n",
    "    train_matched_queries.append(matched_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e9c03e-9be3-404f-8eca-27dfadae05f0",
   "metadata": {},
   "source": [
    "### Few-shot learning on matched train question and chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3775a6-68df-41a8-88e2-4cd88491e57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "chatgpt_train_fewshot_query = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if idx < 3:\n",
    "    if (idx > -1) and (idx < 200):\n",
    "    \n",
    "        test_question = row['question_text']\n",
    "        \n",
    "        test_masked_question = row['masked_question']\n",
    "\n",
    "        train_question_idx = train.index[train['question_text'] == test_question].tolist()\n",
    "\n",
    "        if len(train_question_idx) > 0: # find a matched train question, skip to generate new query\n",
    "            chatgpt_train_fewshot_query.append(train.iloc[train_question_idx[0]]['sparql_query'])\n",
    "\n",
    "        else:\n",
    "            \n",
    "            test_masked_question_embedding = get_embedding(\n",
    "                test_masked_question,\n",
    "                engine=\"text-embedding-ada-002\"\n",
    "            )\n",
    "\n",
    "            train_masked_embeddings_similarities = train.train_masked_question_embedding.\\\n",
    "            apply(lambda x: cosine_similarity(x,test_masked_question_embedding))\n",
    "\n",
    "            top5_idx = train_masked_embeddings_similarities.sort_values(ascending=False)[:5].index\n",
    "\n",
    "            top5_train_masked_questions = list(train.iloc[top5_idx].masked_question.values)\n",
    "            top5_train_masked_queries = list(train.iloc[top5_idx].masked_query.values)\n",
    "            top5_masked_cots = list(train.iloc[top5_idx].masked_cot.values)\n",
    "            \n",
    "            top5_train_questions = list(train.iloc[top5_idx].question_text.values)\n",
    "            top5_train_queries = list(train.iloc[top5_idx].sparql_query.values)\n",
    "            top5_cots = list(train.iloc[top5_idx].train_cot.values)\n",
    "            \n",
    "            msg = \"\"\"\n",
    "               Study the following example question, logical steps, \n",
    "               and SPARQL query provided:\n",
    "           \n",
    "               Question:{}\n",
    "               Logical steps:{}\n",
    "               SPARQL query: {}\n",
    "           \n",
    "               Now, using the learned pattern and logical steps, translate \n",
    "               the new question below into a SPARQL query.\n",
    "               Write a syntactically corect SPARQL query only.\n",
    "               The query should return answers as {}.\n",
    "               Include all required prefixes in the query. \n",
    "               No comments. Output query only.\n",
    "               \n",
    "               New question: {}\n",
    "               Query: \n",
    "            \"\"\"\n",
    "            msg = msg.format(top5_train_questions[0], top5_cots[0], \\\n",
    "                             top5_train_queries[0], answertype_text, test_question)\n",
    "\n",
    "            #print(msg)\n",
    "            \n",
    "            response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\":\"system\", \"content\":\"Reset your memory and start with a \\\n",
    "                 clean slate. Disregard any previous information or context from \\\n",
    "                 our conversation. \"},\n",
    "                {\"role\": \"system\", \"content\": \"Now you are a helpful assistant focusing on DBpedia. \\\n",
    "                You translate a user question to a SPARQL query to answer the question \\\n",
    "                using the DBpedia knowledge base.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "            chatgpt_train_fewshot_query.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ddd9e-4075-4fc7-9e42-393af9c69d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a4eee-61d6-4aea-8094-04d7cc9f1b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_nomasked_train_cot_fewshot_query'] = chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49167e-0637-401f-9437-dd4d01a7d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7054c28-f41b-4dbe-bd03-57176a447272",
   "metadata": {},
   "source": [
    "### Retrieve chatgpt_train_cot_fewshot_query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849ffc5-2798-4508-aae8-f3cfcad100d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the chatgpt_train_3fewshot_query_results\n",
    "# query the DBpedia endpoint in\n",
    "# March, 2023\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "chatgpt_train_cot_fewshot_query_results = []\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    chatgpt_train_fewshot_query = row['chatgpt_nomasked_train_cot_fewshot_query']\n",
    "    \n",
    "    sparql.setQuery(chatgpt_train_fewshot_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        chatgpt_train_cot_fewshot_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        chatgpt_train_cot_fewshot_query_results.append(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea01845-cfd9-4332-b3e0-660b2bd43dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_nomasked_train_cot_fewshot_query_results'] = chatgpt_train_cot_fewshot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279eab46-8b09-4e4c-abe8-07b8439d2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29d27d-1fcf-4561-b511-85045a8bc8cd",
   "metadata": {},
   "source": [
    "### Few-shot learning on matched train question only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c923441-65d0-43f4-b4cb-2edfc84ccb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0956ec-85d2-4285-b915-3b489d591216",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c73fec4-38f9-4216-84f7-2aa430e31d76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "chatgpt_train_fewshot_query = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if idx < 3:\n",
    "    if (idx > -1) and (idx < 200):\n",
    "    \n",
    "        test_question = row['question_text']\n",
    "        \n",
    "        test_masked_question = row['masked_question']\n",
    "\n",
    "        train_question_idx = train.index[train['question_text'] == test_question].tolist()\n",
    "\n",
    "        if len(train_question_idx) > 0: # find a matched train question, skip to generate new query\n",
    "            chatgpt_train_fewshot_query.append(train.iloc[train_question_idx[0]]['sparql_query'])\n",
    "\n",
    "        else:\n",
    "            \n",
    "            test_masked_question_embedding = get_embedding(\n",
    "                test_masked_question,\n",
    "                engine=\"text-embedding-ada-002\"\n",
    "            )\n",
    "\n",
    "            train_masked_embeddings_similarities = train.train_masked_question_embedding.\\\n",
    "            apply(lambda x: cosine_similarity(x,test_masked_question_embedding))\n",
    "\n",
    "            top5_idx = train_masked_embeddings_similarities.sort_values(ascending=False)[:5].index\n",
    "\n",
    "            top5_train_masked_questions = list(train.iloc[top5_idx].masked_question.values)\n",
    "            top5_train_masked_queries = list(train.iloc[top5_idx].masked_query.values)\n",
    "            top5_masked_cots = list(train.iloc[top5_idx].masked_cot.values)\n",
    "            \n",
    "            top5_train_questions = list(train.iloc[top5_idx].question_text.values)\n",
    "            top5_train_queries = list(train.iloc[top5_idx].sparql_query.values)\n",
    "            top5_cots = list(train.iloc[top5_idx].train_cot.values)\n",
    "            \n",
    "            msg = \"\"\"\n",
    "               Study the following example question and SPARQL query provided:\n",
    "           \n",
    "               Question:{}\n",
    "               SPARQL query: {}\n",
    "           \n",
    "               Now, using the learned pattern to translate \n",
    "               the new question below into a SPARQL query.\n",
    "               Write a syntactically corect SPARQL query only.\n",
    "               The query should return answers as {}.\n",
    "               Include all required prefixes in the query. \n",
    "               No comments. Output query only.\n",
    "               \n",
    "               New question: {}\n",
    "               Query: \n",
    "            \"\"\"\n",
    "            msg = msg.format(top5_train_questions[0], \\\n",
    "                             top5_train_queries[0], answertype_text, test_question)\n",
    "\n",
    "            #print(msg)\n",
    "            \n",
    "            response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\":\"system\", \"content\":\"Reset your memory and start with a \\\n",
    "                 clean slate. Disregard any previous information or context from \\\n",
    "                 our conversation. \"},\n",
    "                {\"role\": \"system\", \"content\": \"Now you are a helpful assistant focusing on DBpedia. \\\n",
    "                You translate a user question to a SPARQL query to answer the question \\\n",
    "                using the DBpedia knowledge base.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "            chatgpt_train_fewshot_query.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba640435-669f-4c85-987e-a67ad0cf6ca3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c8089-910f-4d9c-bb45-dd985941f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_train_fewshot_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32931b61-1224-432a-b744-13da3c498cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_nomasked_train_only_fewshot_query'] = chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9fe5b-d02d-4747-954a-ef72df3edf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e09263-1a8d-49a1-93fe-665bbe63fceb",
   "metadata": {},
   "source": [
    "### Retrieve chatgpt_train_only_fewshot_query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83423519-c2b4-41b4-9825-e2a79fd57682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the chatgpt_train_3fewshot_query_results\n",
    "# query the DBpedia endpoint in\n",
    "# March, 2023\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "chatgpt_train_cot_fewshot_query_results = []\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    chatgpt_train_fewshot_query = row['chatgpt_nomasked_train_only_fewshot_query']\n",
    "    \n",
    "    sparql.setQuery(chatgpt_train_fewshot_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        chatgpt_train_cot_fewshot_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        chatgpt_train_cot_fewshot_query_results.append(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95d7288-7ef8-4cb3-bbfd-100e2295d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_nomasked_train_only_fewshot_query_results'] = chatgpt_train_cot_fewshot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066badb-a633-45b3-8315-510754beb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa8309b-9e10-4d73-9ac9-67d68235bb64",
   "metadata": {},
   "source": [
    "### Few-shot learning on matched train question 3-shot only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc47c1d-644b-4754-b552-ca6b76e8734a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "chatgpt_train_fewshot_query = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if idx < 3:\n",
    "    if (idx > 51) and (idx < 200):\n",
    "    \n",
    "        test_question = row['question_text']\n",
    "        \n",
    "        test_masked_question = row['masked_question']\n",
    "\n",
    "        train_question_idx = train.index[train['question_text'] == test_question].tolist()\n",
    "\n",
    "        if len(train_question_idx) > 0: # find a matched train question, skip to generate new query\n",
    "            chatgpt_train_fewshot_query.append(train.iloc[train_question_idx[0]]['sparql_query'])\n",
    "\n",
    "        else:\n",
    "            \n",
    "            test_masked_question_embedding = get_embedding(\n",
    "                test_masked_question,\n",
    "                engine=\"text-embedding-ada-002\"\n",
    "            )\n",
    "\n",
    "            train_masked_embeddings_similarities = train.train_masked_question_embedding.\\\n",
    "            apply(lambda x: cosine_similarity(x,test_masked_question_embedding))\n",
    "\n",
    "            top5_idx = train_masked_embeddings_similarities.sort_values(ascending=False)[:5].index\n",
    "\n",
    "            top5_train_masked_questions = list(train.iloc[top5_idx].masked_question.values)\n",
    "            top5_train_masked_queries = list(train.iloc[top5_idx].masked_query.values)\n",
    "            top5_masked_cots = list(train.iloc[top5_idx].masked_cot.values)\n",
    "            \n",
    "            top5_train_questions = list(train.iloc[top5_idx].question_text.values)\n",
    "            top5_train_queries = list(train.iloc[top5_idx].sparql_query.values)\n",
    "            top5_cots = list(train.iloc[top5_idx].train_cot.values)\n",
    "            \n",
    "            msg = \"\"\"\n",
    "               Study the following example questions and SPARQL queries provided:\n",
    "           \n",
    "               Question:{}\n",
    "               SPARQL query: {}\n",
    "               \n",
    "               Question:{}\n",
    "               SPARQL query: {}\n",
    "               \n",
    "               Question:{}\n",
    "               SPARQL query: {}\n",
    "           \n",
    "               Now, using the learned patterns to translate \n",
    "               the new question below into a SPARQL query.\n",
    "               Write a syntactically corect SPARQL query only.\n",
    "               The query should return answers as {}.\n",
    "               Include all required prefixes in the query. \n",
    "               No comments. Output query only.\n",
    "               \n",
    "               New question: {}\n",
    "               Query: \n",
    "            \"\"\"\n",
    "            msg = msg.format(top5_train_questions[0], top5_train_queries[0], \\\n",
    "                             top5_train_questions[1], top5_train_queries[1], \\\n",
    "                             top5_train_questions[2], top5_train_queries[2], \\\n",
    "                             answertype_text, test_question)\n",
    "\n",
    "            #print(msg)\n",
    "            \n",
    "            response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\":\"system\", \"content\":\"Reset your memory and start with a \\\n",
    "                 clean slate. Disregard any previous information or context from \\\n",
    "                 our conversation. \"},\n",
    "                {\"role\": \"system\", \"content\": \"Now you are a helpful assistant focusing on DBpedia. \\\n",
    "                You translate a user question to a SPARQL query to answer the question \\\n",
    "                using the DBpedia knowledge base.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "            )\n",
    "\n",
    "\n",
    "            chatgpt_train_fewshot_query.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30f07e3-4572-4e9b-81a5-cfa4b30f8ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_train_fewshot_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639dd21e-07eb-42e1-8356-64ac0735678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['chatgpt_nomasked_train_only_3fewshot_query'] = chatgpt_train_fewshot_query\n",
    "test['chatgpt_nomasked_train_only_3fewshot_query'] = temp_query_52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9deee-780b-417c-88c9-2d1c52073ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832470e5-26e7-4b27-941e-cac3f805aa78",
   "metadata": {},
   "source": [
    "### Retrieve chatgpt_train_only_3fewshot_query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6b89d4-5a0b-4bed-ad7d-461b4f06d5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the chatgpt_train_3fewshot_query_results\n",
    "# query the DBpedia endpoint in\n",
    "# March, 2023\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "chatgpt_train_cot_fewshot_query_results = []\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break\n",
    "     \n",
    "    count += 1\n",
    "    chatgpt_train_fewshot_query = row['chatgpt_nomasked_train_only_3fewshot_query']\n",
    "    \n",
    "    sparql.setQuery(chatgpt_train_fewshot_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        chatgpt_train_cot_fewshot_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        chatgpt_train_cot_fewshot_query_results.append(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed54b5-e825-43a0-bc04-d00afc9d4e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['chatgpt_nomasked_train_only_3fewshot_query_results'] = chatgpt_train_cot_fewshot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd519de-6969-4a54-8c48-cebfb8406bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f83b1e-56ff-4032-944a-4e2d0f806918",
   "metadata": {},
   "source": [
    "### Evaluate the chatgpt_train_only_3fewshot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edbcfc1-b236-49f3-9772-2fc2779bb131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3ea9d9-2c48-4e0d-a2f6-ff179050b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cf4f2-6fa6-4d6f-bb55-4c2b5cfb0594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve query results\n",
    "import ast\n",
    "\n",
    "query_results_terms = []\n",
    "count = 0\n",
    "for idx, row in test.iterrows():\n",
    "    try:\n",
    "        bindings = ast.literal_eval(row['gold_query_results_DBpedia_2023_03'])['results']['bindings']\n",
    "\n",
    "        answer_list = []\n",
    "        for item in bindings:\n",
    "            for k in item:\n",
    "                answer_list.append(item[k]['value'])\n",
    "\n",
    "        terms = []\n",
    "        for ans in answer_list:\n",
    "            terms.append(ans.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower())\n",
    "        #if terms not in answer_terms:\n",
    "        query_results_terms.append(terms)\n",
    "              \n",
    "    except:\n",
    "        print(row['gold_query_results_DBpedia_2023_03'])\n",
    "        ex_ans = ast.literal_eval(row['gold_query_results_DBpedia_2023_03'])['boolean']\n",
    "        if ex_ans:\n",
    "            query_results_terms.append([str(ex_ans).lower()])\n",
    "        else:\n",
    "            query_results_terms.append([])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bf97c-f58a-4b69-9323-e94ca161df5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(query_results_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbac5a3-81d6-4b90-9261-b09e9f14234f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_results_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578563e3-f025-4e72-a476-7c96111af9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e592f3-9779-4b6e-b63f-77f25aa762b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve chatgpt train 3fewshot query results\n",
    "import ast\n",
    "\n",
    "chatgpt_query_results_terms = []\n",
    "count = 0\n",
    "for idx, row in test.iterrows():\n",
    "    try:\n",
    "        bindings = row['chatgpt_nomasked_train_only_3fewshot_query_results']['results']['bindings']\n",
    "        #bindings = ast.literal_eval(row['chatgpt_train_1fewshot_query_results'])['results']['bindings']\n",
    "\n",
    "        answer_list = []\n",
    "        for item in bindings:\n",
    "            for k in item:\n",
    "                answer_list.append(item[k]['value'])\n",
    "\n",
    "        terms = []\n",
    "        for ans in answer_list:\n",
    "            terms.append(ans.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower())\n",
    "        #if terms not in answer_terms:\n",
    "        chatgpt_query_results_terms.append(terms)\n",
    "    except TypeError:\n",
    "        chatgpt_query_results_terms.append(['ERROR ERROR ERROR'])\n",
    "    except SyntaxError:\n",
    "        chatgpt_query_results_terms.append(['ERROR ERROR ERROR'])\n",
    "              \n",
    "    except:\n",
    "        print(row['chatgpt_nomasked_train_only_3fewshot_query_results'])\n",
    "        ex_ans = row['chatgpt_nomasked_train_only_3fewshot_query_results']['boolean']\n",
    "        #ex_ans = ast.literal_eval(row['chatgpt_train_1fewshot_query_results'])['boolean']\n",
    "        if ex_ans:\n",
    "            chatgpt_query_results_terms.append([str(ex_ans).lower()])\n",
    "        else:\n",
    "            chatgpt_query_results_terms.append([])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ac31a-80b9-4159-9094-9f4eb7accbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_query_results_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01409dfe-9c42-433c-95a0-c8b814e6cee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chatgpt_query_results_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e91bfd-dd91-437a-97b6-17ab145eaf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the precision and recall based on the total numbers of \n",
    "# gold answers and predicted answers\n",
    "predicted = 0\n",
    "gold = 0\n",
    "predicted_correct = 0\n",
    "some_matched = {}\n",
    "pre_gold_lengths = []\n",
    "for idx, pred_terms in enumerate(chatgpt_query_results_terms):\n",
    "    \n",
    "    gold_terms = query_results_terms[idx]\n",
    "    \n",
    "    predicted +=  len(pred_terms)\n",
    "    gold += len(gold_terms)\n",
    "    \n",
    "    pre_gold_lengths.append((idx, len(pred_terms), len(gold_terms)))\n",
    "    \n",
    "    if (len(pred_terms) > 0) and (len(gold_terms) > 0):\n",
    "        predicted_correct_idx = False\n",
    "        for pterm in pred_terms:\n",
    "            if len(pterm) > 0: # skip an empty string\n",
    "                for gterm in gold_terms:\n",
    "                    if len(gterm) > 0:\n",
    "                        #if pterm ==  gterm:\n",
    "                        pterm = pterm.replace(\"_\", \" \")\n",
    "                        gterm = gterm.replace(\"_\", \" \")\n",
    "                        if (pterm in gterm) or (gterm in pterm):\n",
    "                            predicted_correct_idx = True\n",
    "                            predicted_correct += 1\n",
    "                            #break # this pterm is a correct prediction, skip to next pterm\n",
    "                                    # don't double count this pterm anymore\n",
    "\n",
    "        some_matched[idx] = predicted_correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135511f-2a98-491e-bfa9-f520b5be9d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_gold_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e699bc-7826-4f4d-9c90-ba033c1fd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_matched[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b00f3-f2f6-428b-abe8-0fdbc8eb2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = predicted_correct / (predicted)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c97b2-64b5-4bed-b8f7-0d349fa85345",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = predicted_correct/gold\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb6099-0331-46d8-9b78-306b6ad40e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 / (1/precision + 1/recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ffef44-4cc4-4a4e-b37c-417efd9b1330",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_precision = (predicted_correct-240) / (predicted - 240)\n",
    "adj_recall = (predicted_correct-240) / (gold - 1714)\n",
    "adj_f1 = 2 / (1/adj_precision +  1/adj_recall)\n",
    "print('adj_precision:{},\\nadj_recall:{},\\nadj_f1:{}'.format(adj_precision, adj_recall, adj_f1))\n",
    "predicted_correct, predicted, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2515f40b-8950-4504-afc5-ff628b3477f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the precision and recall based on the total numbers of test questions\n",
    "count = 0\n",
    "predicted_correct = 0\n",
    "some_matched = {}\n",
    "for idx, pred_terms in enumerate(chatgpt_query_results_terms):\n",
    "    gold_terms = query_results_terms[idx]\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if (len(pred_terms) > 0) and (len(gold_terms) > 0):\n",
    "        predicted_correct_idx = False\n",
    "        for pterm in pred_terms:\n",
    "            if len(pterm) > 0: # skip an empty string\n",
    "                for gterm in gold_terms:\n",
    "                    if len(gterm) > 0:\n",
    "                        #if pterm ==  gterm:\n",
    "                        #pterm = pterm.replace(\"_\", \" \")\n",
    "                        #gterm = gterm.replace(\"_\", \" \")\n",
    "                        if not predicted_correct_idx:\n",
    "                            #if (pterm in gterm) or (gterm in pterm):\n",
    "                            if pterm == gterm:\n",
    "                                predicted_correct_idx = True\n",
    "                                predicted_correct += 1\n",
    "                        else:\n",
    "                            pass\n",
    "                \n",
    "        some_matched[idx] = predicted_correct_idx\n",
    "    elif (len(pred_terms) == 0) and (len(gold_terms) == 0):\n",
    "        predicted_correct += 1\n",
    "        some_matched[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935a304-4637-4e45-9143-769ee1a8c887",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for k in some_matched:\n",
    "    if some_matched[k]:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ececd388-c952-4a13-894d-232cd67a2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df35502-370a-4128-8263-9f03b928d9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb6a06-b172-401f-bf51-7d652014c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = predicted_correct / count\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727eba12-2c97-434a-bd58-3282b44bc780",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = predicted_correct/count\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bb018-64de-4ba6-87bb-a7e0edaaad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 / (1/precision + 1/recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86015c34-a67a-4dc6-94ce-ca969ec0356a",
   "metadata": {},
   "source": [
    "### Explain test query in chain of thought without word limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afcf870-9486-4641-89a2-b8cc8010f85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cot = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if count > 4:\n",
    "    #    break\n",
    "    count += 1\n",
    "    \n",
    "    test_query = row['sparql_query']\n",
    "    \n",
    "    #if idx < 3:\n",
    "    if (idx > 123) and (idx < 200):\n",
    "        msg = \"\"\"\n",
    "               Briefly explain the following query in logical steps as a chain of thought. \n",
    "               Explain in natural language. \n",
    "               Forget what you have about the query before. \n",
    "               Assume you are trying to construct the query again. \n",
    "               No comments. Output the steps only. \n",
    "               Do not include the original query in the explanation. \n",
    "\n",
    "               QUERY:{}\n",
    "               THOUGHT:\n",
    "        \"\"\"\n",
    "        msg = msg.format(test_query)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on DBpedia.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        cot.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695296da-f506-4501-a05e-b193d2c84ee2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7569fe82-29a3-4893-92c8-85fecd1219f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cot_noWordLimit']=temp_cot_124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209176e-725f-4cef-a8d5-c32c5b43af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a776a9c-cec5-4284-8c92-95f1d89e0711",
   "metadata": {},
   "source": [
    "### ChatGPT get test query based on ChainOfThought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b0204-4e92-4c99-8c50-2d3279a67c3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "chatgpt_cot_query = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    \n",
    "    #if count > 4:\n",
    "    #    break\n",
    "    count += 1\n",
    "    \n",
    "    test_question = row['question_text']\n",
    "\n",
    "    cot = row['cot_noWordLimit']\n",
    "    \n",
    "    answertype = row['answertype']\n",
    "    answertype_text = \"\"\n",
    "    if answertype == 'resource':\n",
    "        answertype_text = 'DBpedia Resource URI(s)'\n",
    "    else:\n",
    "        answertype_text = answertype\n",
    "    \n",
    "    #if idx < 3:\n",
    "    if (idx > 120) and (idx < 200):\n",
    "        msg = \"\"\"\n",
    "               Translate the question to SPARQL query on DBpedia. \n",
    "               Forget what you have about the question and query before. \n",
    "               Follow the steps in the chain of thought to construct the query. \n",
    "               Output query only. No comments. \n",
    "               Include all required prefixes in the query. \n",
    "               Return the answers as {}.\n",
    "\n",
    "               QUESTION: {}\n",
    "\n",
    "               THOUGHT: {}\n",
    "\n",
    "               QUERY: \n",
    "        \"\"\"\n",
    "        msg = msg.format(answertype_text, test_question, cot)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on DBpedia. \\\n",
    "                You will translate a user question to a SPARQL query on the DBpedia knowledge base.\"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        chatgpt_cot_query.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7851f2c-bade-4892-86ad-aca7abe9ced9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['chatgpt_cot_noWordLimit_query'] = temp_cot_query_121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7820b-1e92-4815-821d-5b6e4d3d10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66e198-beac-4a22-bf21-1ea2fb4d31a1",
   "metadata": {},
   "source": [
    "### Retrieve chatgpt_cot_noWordLimit_query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940e048d-f986-457f-8d46-c94a6dc88121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve the chatgpt_cot_query_results\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "# set up the SPARQL endpoint URL\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "chatgpt_cot_query_results = []\n",
    "count = 0\n",
    "for idx, row in tqdm(test.iterrows(), total=test.shape[0]):\n",
    "    #if count > 3:\n",
    "    #    break \n",
    "    count += 1\n",
    "    \n",
    "    gpt_query = row['chatgpt_cot_noWordLimit_query']\n",
    "    \n",
    "    sparql.setQuery(gpt_query)\n",
    "    \n",
    "    try:\n",
    "        ret = sparql.queryAndConvert()\n",
    "\n",
    "        chatgpt_cot_query_results.append(ret)\n",
    "    except Exception as e:\n",
    "        chatgpt_cot_query_results.append(e)\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa9c951-3c5b-45b3-a414-6b7e68efd343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test['chatgpt_cot_noWordLimit_query_results'] = chatgpt_cot_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fe9696-2729-460d-ada0-07a288f1b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test.to_csv('../data/QALD/9/data/qald-9-test-with-embeddings-cot.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae502bd-f402-43f6-b468-3dfbac7fa142",
   "metadata": {},
   "source": [
    "### Evaluate the chatgpt_cot_noWordLimit_query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6645d978-6f36-4c73-960a-06db90d8393a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve query results\n",
    "import ast\n",
    "\n",
    "query_results_terms = []\n",
    "count = 0\n",
    "for idx, row in test.iterrows():\n",
    "    try:\n",
    "        bindings = ast.literal_eval(row['gold_query_results_DBpedia_2023_03'])['results']['bindings']\n",
    "\n",
    "        answer_list = []\n",
    "        for item in bindings:\n",
    "            for k in item:\n",
    "                answer_list.append(item[k]['value'])\n",
    "\n",
    "        terms = []\n",
    "        for ans in answer_list:\n",
    "            terms.append(ans.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower())\n",
    "        #if terms not in answer_terms:\n",
    "        query_results_terms.append(terms)\n",
    "              \n",
    "    except:\n",
    "        print(row['gold_query_results_DBpedia_2023_03'])\n",
    "        ex_ans = ast.literal_eval(row['gold_query_results_DBpedia_2023_03'])['boolean']\n",
    "        if ex_ans:\n",
    "            query_results_terms.append([str(ex_ans).lower()])\n",
    "        else:\n",
    "            query_results_terms.append([])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa138b-dea2-48c1-96fd-2bfc82847201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(query_results_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b491c-25d1-41e8-abb6-f0f55a098e14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve gpt query results\n",
    "import ast\n",
    "\n",
    "chatgpt_cot_query_results_terms = []\n",
    "count = 0\n",
    "for idx, row in test.iterrows():\n",
    "    try:\n",
    "        #bindings = ast.literal_eval(row['gpt_fewshot_query_results'])['results']['bindings']\n",
    "        bindings = row['chatgpt_cot_noWordLimit_query_results']['results']['bindings']\n",
    "\n",
    "        answer_list = []\n",
    "        for item in bindings:\n",
    "            for k in item:\n",
    "                answer_list.append(item[k]['value'])\n",
    "\n",
    "        terms = []\n",
    "        for ans in answer_list:\n",
    "            terms.append(ans.replace('http://dbpedia.org/resource/', '').replace('dbo:', '').strip().lower())\n",
    "        #if terms not in answer_terms:\n",
    "        chatgpt_cot_query_results_terms.append(terms)\n",
    "    except SyntaxError:\n",
    "        chatgpt_cot_query_results_terms.append(['ERROR ERROR ERROR'])\n",
    "        \n",
    "    except TypeError:\n",
    "        chatgpt_cot_query_results_terms.append(['ERROR ERROR ERROR'])\n",
    "              \n",
    "    except:\n",
    "        print(row['chatgpt_cot_noWordLimit_query_results'])\n",
    "        #ex_ans = ast.literal_eval(row['gpt_query_fewshot_results_DBpedia'])['boolean']\n",
    "        ex_ans = row['chatgpt_cot_noWordLimit_query_results']['boolean']\n",
    "        if ex_ans:\n",
    "            chatgpt_cot_query_results_terms.append([str(ex_ans).lower()])\n",
    "        else:\n",
    "            chatgpt_cot_query_results_terms.append([])\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d0d65-cf8f-47ba-904c-4ba7429df51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chatgpt_cot_query_results_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e6f38-0521-4abd-b94e-737cf5a3eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the precision and recall based on the total numbers of \n",
    "# gold answers and predicted answers\n",
    "predicted = 0\n",
    "gold = 0\n",
    "predicted_correct = 0\n",
    "some_matched = {}\n",
    "\n",
    "pred_gold_lengths = []\n",
    "for idx, pred_terms in enumerate(chatgpt_cot_query_results_terms):\n",
    "    \n",
    "    gold_terms = query_results_terms[idx]\n",
    "    \n",
    "    predicted +=  len(pred_terms)\n",
    "    gold += len(gold_terms)\n",
    "    \n",
    "    pred_gold_lengths.append((idx, len(pred_terms), len(gold_terms)))\n",
    "    \n",
    "    if (len(pred_terms) > 0) and (len(gold_terms) > 0):\n",
    "\n",
    "        predicted_correct_idx = False\n",
    "        for pterm in pred_terms:\n",
    "            if len(pterm) > 0: # skip an empty string\n",
    "                for gterm in gold_terms:\n",
    "                    if len(gterm) > 0:\n",
    "                        if pterm ==  gterm:\n",
    "                        #pterm = pterm.replace(\"_\", \" \")\n",
    "                        #gterm = gterm.replace(\"_\", \" \")\n",
    "                        #if (pterm in gterm) or (gterm in pterm):\n",
    "                            predicted_correct_idx = True\n",
    "                            predicted_correct += 1\n",
    "                            break # this pterm is a correct prediction, skip to next pterm\n",
    "                                    # don't double count this pterm anymore\n",
    "\n",
    "        some_matched[idx] = predicted_correct_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811dcc54-c652-4bf2-aed3-5a6e29517e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_gold_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e5b3e-97eb-4e6d-bed2-08097c82e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = 0\n",
    "gols = 0\n",
    "for _, pre, gol in pred_gold_lengths:\n",
    "    pres += pre\n",
    "    gols += gol\n",
    "pres, gols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887a389-c4bb-4287-b11c-872209005853",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (predicted_correct) / (predicted)\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6d890-b27e-4025-9484-cf6640f352ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = predicted_correct/gold\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1980184b-f92d-4580-9a75-0d7e35648902",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 / (1/precision + 1/recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38098ad-945a-466f-b79e-f619f927edcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_precision = (predicted_correct - 240) / (predicted - 10000 -1)\n",
    "adj_recall = (predicted_correct - 240) / (gold - 44 - 1714)\n",
    "adj_f1 = 2 / (1/adj_precision +  1/adj_recall)\n",
    "print('adj_precision:{},\\nadj_recall:{},\\nadj_f1:{}'.format(adj_precision, adj_recall, adj_f1))\n",
    "predicted_correct, predicted, gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a282e5e-ccc6-4744-b5ba-7427d511cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the precision and recall based on the total numbers of test questions\n",
    "count = 0\n",
    "predicted_correct = 0\n",
    "some_matched = {}\n",
    "for idx, pred_terms in enumerate(chatgpt_cot_query_results_terms):\n",
    "    gold_terms = query_results_terms[idx]\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    if (len(pred_terms) > 0) and (len(gold_terms) > 0):\n",
    "        predicted_correct_idx = False\n",
    "        for pterm in pred_terms:\n",
    "            if len(pterm) > 0: # skip an empty string\n",
    "                for gterm in gold_terms:\n",
    "                    if len(gterm) > 0:\n",
    "                        pterm = pterm.replace(\"_\", \" \")\n",
    "                        gterm = gterm.replace(\"_\", \" \")\n",
    "                        if not predicted_correct_idx:\n",
    "                            if (pterm in gterm) or (gterm in pterm):\n",
    "                                predicted_correct_idx = True\n",
    "                                predicted_correct += 1\n",
    "                        else:\n",
    "                            pass\n",
    "                \n",
    "        some_matched[idx] = predicted_correct_idx\n",
    "    elif (len(pred_terms) == 0) and (len(gold_terms) == 0):\n",
    "        predicted_correct += 1\n",
    "        some_matched[idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8387caf-361a-4db0-a4d7-c64fb9372f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for k in some_matched:\n",
    "    if some_matched[k]:\n",
    "        total += 1\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a400739c-00c7-411e-b86d-d76e88fecb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6ea6d-2344-4613-bec1-c59af7b4a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a5e27-2711-4661-b45f-bf7d39919b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = predicted_correct / count\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e73c6-4326-4985-9d44-fcd40a15b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = predicted_correct/count\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d880d0-a1b9-4fd4-ba4b-74edab8a93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2 / (1/precision + 1/recall)\n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ddcec-bee1-4308-9054-f18fbfa2a7f8",
   "metadata": {},
   "source": [
    "### Explain train query in chain of thought and few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230cc67f-f83f-4754-bf90-bd2608749321",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d43137-d92c-4f37-b1b8-2595530a44ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_cot = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, row in tqdm(train.iterrows(), total=train.shape[0]):\n",
    "    \n",
    "    #if count > 4:\n",
    "    #    break\n",
    "    count += 1\n",
    "    \n",
    "    if idx > 290:\n",
    "        train_query = row['sparql_query']\n",
    "\n",
    "\n",
    "        msg = \"\"\"\n",
    "               Briefly explain the following query in logical steps as a chain of thought. \n",
    "               Explain in natural language. \n",
    "               Forget what you have about the query before. \n",
    "               Assume you are trying to construct the query again. \n",
    "               No comments. Output the steps only. \n",
    "               Do not include the original query in the explanation. \n",
    "\n",
    "               QUERY:{}\n",
    "               THOUGHT:\n",
    "        \"\"\"\n",
    "        msg = msg.format(train_query)\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": \"you are a helpful assistant focusing on DBpedia. \\\n",
    "                 You will explain SPARQL query in logical steps to help reconstruct the query. \"},\n",
    "                {\"role\": \"user\", \"content\": msg}\n",
    "                ]\n",
    "        )\n",
    "\n",
    "\n",
    "        train_cot.append(response['choices'][0]['message']['content'].\\\n",
    "                                       strip().replace('\\n', ' ' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332f95b-b5d2-4373-89ab-9fe5dd5f52b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['train_cot']=train_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bd351-5d56-45a3-bc73-7a2733bc39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.to_csv('../data/QALD/9/data/qald-9-train-with-embeddings-cot.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mof_kg",
   "language": "python",
   "name": "mof_kg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
